# ã‚‚ã†éŸ³å£°å¤‰æ›ã§è¿·ã‚ãªã„ï¼GCP Speech-to-Text & Text-to-Speechã‚’TypeScriptã§å®Œå…¨åˆ¶å¾¡ã™ã‚‹éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã‚¬ã‚¤ãƒ‰

## ã¯ã˜ã‚ã«

ã€ŒéŸ³å£°èªè­˜æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ãŸã„ã‘ã©ã€ã©ã®APIã‚’ä½¿ãˆã°ã„ã„ã‹ã‚ã‹ã‚‰ãªã„...ã€
ã€Œæ–‡å­—èª­ã¿ä¸Šã’æ©Ÿèƒ½ã‚’ä½œã‚ŠãŸã„ã‘ã©ã€å“è³ªã®é«˜ã„éŸ³å£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„...ã€

ã“ã‚“ãªæ‚©ã¿ã‚’æŠ±ãˆã¦ã„ã‚‹é–‹ç™ºè€…ã®æ–¹ã‚‚å¤šã„ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚

Googleã®Speech-to-Text APIã¨Text-to-Speech APIã‚’ä½¿ãˆã°ã€ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã®é«˜å“è³ªãªéŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’æ¯”è¼ƒçš„ç°¡å˜ã«æ§‹ç¯‰ã§ãã¾ã™ã€‚ã“ã®è¨˜äº‹ã§ã¯ã€TypeScriptã‚’ä½¿ã£ãŸå®Ÿè£…æ–¹æ³•ã‹ã‚‰ã€å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³é‹ç”¨ã¾ã§ã€ä½“ç³»çš„ã«è§£èª¬ã—ã¦ã„ãã¾ã™ã€‚

**ğŸ¯ ã“ã®è¨˜äº‹ã§å­¦ã¹ã‚‹ã“ã¨**

>* GCP Speech-to-Text APIã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã¨å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
>* GCP Text-to-Speech APIã®å¤šè¨€èªãƒ»å¤šéŸ³å£°å¯¾å¿œå®Ÿè£…
>* ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰æ–¹æ³•
>* éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»å¤‰æ›ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®å®Ÿè£…
>* ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
>* æ–™é‡‘ä½“ç³»ã¨é‹ç”¨ã‚³ã‚¹ãƒˆã®æœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯

**ğŸ“‹ å‰ææ¡ä»¶**

>* Node.js 18ä»¥ä¸ŠãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨
>* GCPã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒä½œæˆæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
>* TypeScriptã®åŸºæœ¬çš„ãªçŸ¥è­˜ãŒã‚ã‚‹ã“ã¨
>* åŸºæœ¬çš„ãªGCPã‚µãƒ¼ãƒ“ã‚¹ã®ç†è§£ãŒã‚ã‚‹ã“ã¨

## ğŸš€ GCP Speech-to-Text APIã®å®Ÿè£…

### 1\. ç’°å¢ƒæ§‹ç¯‰ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã¾ãšã¯å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```typescript:src/setup.ts
npm install @google-cloud/speech @google-cloud/text-to-speech
npm install -D @types/node typescript ts-node
```

GCPã®èªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã¾ã™ï¼š

```typescript:src/config/gcp-config.ts
import { SpeechClient } from '@google-cloud/speech';
import { TextToSpeechClient } from '@google-cloud/text-to-speech';

export const speechClient = new SpeechClient({
  projectId: process.env.GCP_PROJECT_ID,
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
});

export const ttsClient = new TextToSpeechClient({
  projectId: process.env.GCP_PROJECT_ID,
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
});

export const GCP_CONFIG = {
  projectId: process.env.GCP_PROJECT_ID || '',
  location: process.env.GCP_LOCATION || 'global',
  bucketName: process.env.GCS_BUCKET_NAME || '',
} as const;
```

ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®šã—ã¾ã™ï¼š

```typescript:.env
GCP_PROJECT_ID=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=./path/to/service-account-key.json
GCP_LOCATION=asia-northeast1
GCS_BUCKET_NAME=your-bucket-name
```

### 2\. Speech-to-Text APIã®åŸºæœ¬å®Ÿè£…

åŸºæœ¬çš„ãªéŸ³å£°èªè­˜æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```typescript:src/services/speech-to-text.service.ts
import { SpeechClient } from '@google-cloud/speech';
import { readFileSync } from 'fs';

export class SpeechToTextService {
  private client: SpeechClient;

  constructor(client: SpeechClient) {
    this.client = client;
  }

  async transcribeAudioFile(audioFilePath: string, languageCode: string = 'ja-JP'): Promise<string> {
    try {
      const audioBytes = readFileSync(audioFilePath).toString('base64');

      const request = {
        audio: {
          content: audioBytes,
        },
        config: {
          encoding: 'WEBM_OPUS' as const,
          sampleRateHertz: 48000,
          languageCode,
          enableAutomaticPunctuation: true,
          enableWordTimeOffsets: true,
          model: 'latest_long',
        },
      };

      const [response] = await this.client.recognize(request);
      
      if (!response.results || response.results.length === 0) {
        throw new Error('éŸ³å£°èªè­˜çµæœãŒç©ºã§ã™');
      }

      const transcription = response.results
        .map(result => result.alternatives?.[0]?.transcript || '')
        .join(' ')
        .trim();

      return transcription;
    } catch (error) {
      console.error('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async transcribeWithConfidence(audioFilePath: string, languageCode: string = 'ja-JP') {
    try {
      const audioBytes = readFileSync(audioFilePath).toString('base64');

      const request = {
        audio: {
          content: audioBytes,
        },
        config: {
          encoding: 'WEBM_OPUS' as const,
          sampleRateHertz: 48000,
          languageCode,
          enableAutomaticPunctuation: true,
          enableWordTimeOffsets: true,
          model: 'latest_long',
          maxAlternatives: 3,
        },
      };

      const [response] = await this.client.recognize(request);
      
      if (!response.results || response.results.length === 0) {
        throw new Error('éŸ³å£°èªè­˜çµæœãŒç©ºã§ã™');
      }

      const results = response.results.map(result => ({
        transcript: result.alternatives?.[0]?.transcript || '',
        confidence: result.alternatives?.[0]?.confidence || 0,
        words: result.alternatives?.[0]?.words?.map(word => ({
          word: word.word || '',
          startTime: word.startTime?.seconds || 0,
          endTime: word.endTime?.seconds || 0,
        })) || [],
        alternatives: result.alternatives?.map(alt => ({
          transcript: alt.transcript || '',
          confidence: alt.confidence || 0,
        })) || [],
      }));

      return results;
    } catch (error) {
      console.error('è©³ç´°éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`è©³ç´°éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }
}
```

### 3\. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã®å®Ÿè£…

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°èªè­˜ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```typescript:src/services/streaming-speech.service.ts
import { SpeechClient } from '@google-cloud/speech';
import { Duplex } from 'stream';

export class StreamingSpeechService {
  private client: SpeechClient;

  constructor(client: SpeechClient) {
    this.client = client;
  }

  createStreamingRecognition(languageCode: string = 'ja-JP') {
    const request = {
      config: {
        encoding: 'WEBM_OPUS' as const,
        sampleRateHertz: 48000,
        languageCode,
        enableAutomaticPunctuation: true,
        model: 'latest_long',
      },
      interimResults: true,
    };

    const recognizeStream = this.client
      .streamingRecognize(request)
      .on('error', (error) => {
        console.error('ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã‚¨ãƒ©ãƒ¼:', error);
      })
      .on('data', (data) => {
        if (data.results?.[0]?.alternatives?.[0]) {
          const result = data.results[0].alternatives[0];
          const isFinal = data.results[0].isFinal;
          
          console.log(`${isFinal ? '[ç¢ºå®š]' : '[æš«å®š]'} ${result.transcript}`);
          
          if (isFinal) {
            console.log(`ä¿¡é ¼åº¦: ${result.confidence}`);
          }
        }
      });

    return recognizeStream;
  }

  async processAudioStream(audioStream: Duplex, languageCode: string = 'ja-JP'): Promise<string[]> {
    return new Promise((resolve, reject) => {
      const recognizeStream = this.createStreamingRecognition(languageCode);
      const transcripts: string[] = [];

      recognizeStream.on('data', (data) => {
        if (data.results?.[0]?.alternatives?.[0] && data.results[0].isFinal) {
          transcripts.push(data.results[0].alternatives[0].transcript);
        }
      });

      recognizeStream.on('error', reject);
      recognizeStream.on('end', () => resolve(transcripts));

      audioStream.pipe(recognizeStream);
    });
  }
}
```

## GCP Text-to-Speech APIã®å®Ÿè£…

### 1\. åŸºæœ¬çš„ãªéŸ³å£°åˆæˆæ©Ÿèƒ½

å¤šè¨€èªå¯¾å¿œã®éŸ³å£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```typescript:src/services/text-to-speech.service.ts
import { TextToSpeechClient } from '@google-cloud/text-to-speech';
import { writeFileSync } from 'fs';

export interface SynthesizeOptions {
  languageCode?: string;
  ssmlGender?: 'NEUTRAL' | 'FEMALE' | 'MALE';
  voiceName?: string;
  audioEncoding?: 'MP3' | 'LINEAR16' | 'OGG_OPUS';
  speakingRate?: number;
  pitch?: number;
  volumeGainDb?: number;
}

export class TextToSpeechService {
  private client: TextToSpeechClient;

  constructor(client: TextToSpeechClient) {
    this.client = client;
  }

  async synthesizeText(
    text: string,
    outputPath: string,
    options: SynthesizeOptions = {}
  ): Promise<void> {
    try {
      const {
        languageCode = 'ja-JP',
        ssmlGender = 'NEUTRAL',
        voiceName,
        audioEncoding = 'MP3',
        speakingRate = 1.0,
        pitch = 0.0,
        volumeGainDb = 0.0,
      } = options;

      const request = {
        input: { text },
        voice: {
          languageCode,
          ssmlGender,
          ...(voiceName && { name: voiceName }),
        },
        audioConfig: {
          audioEncoding,
          speakingRate,
          pitch,
          volumeGainDb,
        },
      };

      const [response] = await this.client.synthesizeSpeech(request);
      
      if (!response.audioContent) {
        throw new Error('éŸ³å£°åˆæˆçµæœãŒç©ºã§ã™');
      }

      writeFileSync(outputPath, response.audioContent, 'binary');
      console.log(`éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: ${outputPath}`);
    } catch (error) {
      console.error('éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async synthesizeSSML(
    ssml: string,
    outputPath: string,
    options: SynthesizeOptions = {}
  ): Promise<void> {
    try {
      const {
        languageCode = 'ja-JP',
        ssmlGender = 'NEUTRAL',
        voiceName,
        audioEncoding = 'MP3',
        speakingRate = 1.0,
        pitch = 0.0,
        volumeGainDb = 0.0,
      } = options;

      const request = {
        input: { ssml },
        voice: {
          languageCode,
          ssmlGender,
          ...(voiceName && { name: voiceName }),
        },
        audioConfig: {
          audioEncoding,
          speakingRate,
          pitch,
          volumeGainDb,
        },
      };

      const [response] = await this.client.synthesizeSpeech(request);
      
      if (!response.audioContent) {
        throw new Error('SSMLéŸ³å£°åˆæˆçµæœãŒç©ºã§ã™');
      }

      writeFileSync(outputPath, response.audioContent, 'binary');
      console.log(`SSMLéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: ${outputPath}`);
    } catch (error) {
      console.error('SSMLéŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`SSMLéŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async getAvailableVoices(languageCode?: string) {
    try {
      const request = languageCode ? { languageCode } : {};
      const [response] = await this.client.listVoices(request);
      
      return response.voices?.map(voice => ({
        name: voice.name,
        languageCodes: voice.languageCodes,
        ssmlGender: voice.ssmlGender,
        naturalSampleRateHertz: voice.naturalSampleRateHertz,
      })) || [];
    } catch (error) {
      console.error('éŸ³å£°ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`éŸ³å£°ãƒªã‚¹ãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }
}
```

### 2\. SSMLå¯¾å¿œã¨é«˜åº¦ãªéŸ³å£°åˆ¶å¾¡

SSMLï¼ˆSpeech Synthesis Markup Languageï¼‰ã‚’ä½¿ã£ãŸé«˜åº¦ãªéŸ³å£°åˆ¶å¾¡ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```typescript:src/services/ssml-builder.service.ts
export class SSMLBuilder {
  private ssml: string = '<speak>';

  constructor() {}

  text(content: string): SSMLBuilder {
    this.ssml += content;
    return this;
  }

  pause(seconds: number): SSMLBuilder {
    this.ssml += `<break time="${seconds}s"/>`;
    return this;
  }

  emphasis(text: string, level: 'strong' | 'moderate' | 'reduced' = 'moderate'): SSMLBuilder {
    this.ssml += `<emphasis level="${level}">${text}</emphasis>`;
    return this;
  }

  prosody(
    text: string,
    options: {
      rate?: 'x-slow' | 'slow' | 'medium' | 'fast' | 'x-fast' | string;
      pitch?: 'x-low' | 'low' | 'medium' | 'high' | 'x-high' | string;
      volume?: 'silent' | 'x-soft' | 'soft' | 'medium' | 'loud' | 'x-loud' | string;
    }
  ): SSMLBuilder {
    let attributes = '';
    if (options.rate) attributes += ` rate="${options.rate}"`;
    if (options.pitch) attributes += ` pitch="${options.pitch}"`;
    if (options.volume) attributes += ` volume="${options.volume}"`;

    this.ssml += `<prosody${attributes}>${text}</prosody>`;
    return this;
  }

  sayAs(text: string, interpretAs: 'characters' | 'spell-out' | 'cardinal' | 'number' | 'ordinal' | 'digits' | 'fraction' | 'unit' | 'date' | 'time' | 'telephone'): SSMLBuilder {
    this.ssml += `<say-as interpret-as="${interpretAs}">${text}</say-as>`;
    return this;
  }

  audio(src: string, alt?: string): SSMLBuilder {
    const altText = alt ? ` alt="${alt}"` : '';
    this.ssml += `<audio src="${src}"${altText}></audio>`;
    return this;
  }

  sub(alias: string, substitute: string): SSMLBuilder {
    this.ssml += `<sub alias="${substitute}">${alias}</sub>`;
    return this;
  }

  build(): string {
    return this.ssml + '</speak>';
  }

  reset(): SSMLBuilder {
    this.ssml = '<speak>';
    return this;
  }

  static createNewsReading(title: string, content: string): string {
    return new SSMLBuilder()
      .emphasis(title, 'strong')
      .pause(1)
      .prosody(content, { rate: 'medium', pitch: 'medium' })
      .build();
  }

  static createPhoneNumber(phoneNumber: string): string {
    return new SSMLBuilder()
      .sayAs(phoneNumber, 'telephone')
      .build();
  }

  static createDateAnnouncement(date: string): string {
    return new SSMLBuilder()
      .text('æœ¬æ—¥ã¯')
      .sayAs(date, 'date')
      .text('ã§ã™')
      .build();
  }
}
```

## çµ±åˆéŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…

Speech-to-Textã¨Text-to-Speechã‚’çµ„ã¿åˆã‚ã›ãŸçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```typescript:src/services/integrated-speech.service.ts
import { SpeechToTextService } from './speech-to-text.service';
import { TextToSpeechService } from './text-to-speech.service';
import { SSMLBuilder } from './ssml-builder.service';

export interface AudioProcessingResult {
  originalAudio: string;
  transcription: string;
  confidence: number;
  processedText: string;
  outputAudio: string;
  processingTime: number;
}

export class IntegratedSpeechService {
  private sttService: SpeechToTextService;
  private ttsService: TextToSpeechService;

  constructor(sttService: SpeechToTextService, ttsService: TextToSpeechService) {
    this.sttService = sttService;
    this.ttsService = ttsService;
  }

  async processAudioToAudio(
    inputAudioPath: string,
    outputAudioPath: string,
    textProcessor?: (text: string) => string,
    languageCode: string = 'ja-JP'
  ): Promise<AudioProcessingResult> {
    const startTime = Date.now();

    try {
      // 1. éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
      console.log('éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™...');
      const recognitionResults = await this.sttService.transcribeWithConfidence(inputAudioPath, languageCode);
      
      if (recognitionResults.length === 0) {
        throw new Error('éŸ³å£°èªè­˜çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ');
      }

      const transcription = recognitionResults[0].transcript;
      const confidence = recognitionResults[0].confidence;

      console.log(`èªè­˜çµæœ: ${transcription}`);
      console.log(`ä¿¡é ¼åº¦: ${confidence}`);

      // 2. ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
      const processedText = textProcessor ? textProcessor(transcription) : transcription;
      
      // 3. å‡¦ç†ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›
      console.log('éŸ³å£°åˆæˆã‚’é–‹å§‹ã—ã¾ã™...');
      await this.ttsService.synthesizeText(processedText, outputAudioPath, { languageCode });

      const processingTime = Date.now() - startTime;

      return {
        originalAudio: inputAudioPath,
        transcription,
        confidence,
        processedText,
        outputAudio: outputAudioPath,
        processingTime,
      };
    } catch (error) {
      console.error('éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async createVoiceBot(
    inputAudioPath: string,
    outputAudioPath: string,
    botResponder: (userMessage: string) => Promise<string>,
    languageCode: string = 'ja-JP'
  ): Promise<AudioProcessingResult> {
    const startTime = Date.now();

    try {
      // 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ã‚’èªè­˜
      console.log('ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ã‚’èªè­˜ä¸­...');
      const transcription = await this.sttService.transcribeAudioFile(inputAudioPath, languageCode);
      console.log(`ãƒ¦ãƒ¼ã‚¶ãƒ¼: ${transcription}`);

      // 2. ãƒœãƒƒãƒˆãŒå¿œç­”ã‚’ç”Ÿæˆ
      console.log('ãƒœãƒƒãƒˆãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...');
      const botResponse = await botResponder(transcription);
      console.log(`ãƒœãƒƒãƒˆ: ${botResponse}`);

      // 3. ãƒœãƒƒãƒˆã®å¿œç­”ã‚’éŸ³å£°ã«å¤‰æ›
      console.log('ãƒœãƒƒãƒˆã®éŸ³å£°ã‚’ç”Ÿæˆä¸­...');
      const ssml = new SSMLBuilder()
        .prosody(botResponse, { rate: 'medium', pitch: 'medium' })
        .build();

      await this.ttsService.synthesizeSSML(ssml, outputAudioPath, { languageCode });

      const processingTime = Date.now() - startTime;

      return {
        originalAudio: inputAudioPath,
        transcription,
        confidence: 1.0, // ãƒœãƒƒãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãªã®ã§ä¿¡é ¼åº¦ã¯æœ€å¤§
        processedText: botResponse,
        outputAudio: outputAudioPath,
        processingTime,
      };
    } catch (error) {
      console.error('éŸ³å£°ãƒœãƒƒãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
      throw new Error(`éŸ³å£°ãƒœãƒƒãƒˆå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async batchProcessAudioFiles(
    inputFiles: string[],
    outputDir: string,
    textProcessor?: (text: string) => string,
    languageCode: string = 'ja-JP'
  ): Promise<AudioProcessingResult[]> {
    const results: AudioProcessingResult[] = [];

    for (let i = 0; i < inputFiles.length; i++) {
      const inputFile = inputFiles[i];
      const outputFile = `${outputDir}/processed_${i + 1}.mp3`;

      try {
        console.log(`å‡¦ç†ä¸­ (${i + 1}/${inputFiles.length}): ${inputFile}`);
        const result = await this.processAudioToAudio(
          inputFile,
          outputFile,
          textProcessor,
          languageCode
        );
        results.push(result);
      } catch (error) {
        console.error(`ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ (${inputFile}):`, error);
        // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
      }
    }

    return results;
  }
}
```

## å®Ÿç”¨ä¾‹ã¨ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…

### 1\. åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```typescript:src/examples/basic-usage.ts
import { speechClient, ttsClient } from '../config/gcp-config';
import { SpeechToTextService } from '../services/speech-to-text.service';
import { TextToSpeechService } from '../services/text-to-speech.service';
import { IntegratedSpeechService } from '../services/integrated-speech.service';
import { SSMLBuilder } from '../services/ssml-builder.service';

async function basicExample() {
  // ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
  const sttService = new SpeechToTextService(speechClient);
  const ttsService = new TextToSpeechService(ttsClient);
  const integratedService = new IntegratedSpeechService(sttService, ttsService);

  try {
    // 1. éŸ³å£°èªè­˜ã®ãƒ†ã‚¹ãƒˆ
    console.log('=== éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ ===');
    const transcription = await sttService.transcribeAudioFile('./input/sample.wav', 'ja-JP');
    console.log(`èªè­˜çµæœ: ${transcription}`);

    // 2. éŸ³å£°åˆæˆã®ãƒ†ã‚¹ãƒˆ
    console.log('\n=== éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆ ===');
    await ttsService.synthesizeText(
      'ã“ã‚“ã«ã¡ã¯ã€Google Cloud Platform ã®éŸ³å£°APIã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚',
      './output/basic-test.mp3',
      {
        languageCode: 'ja-JP',
        ssmlGender: 'FEMALE',
        speakingRate: 1.0,
        pitch: 0.0,
      }
    );

    // 3. SSMLéŸ³å£°åˆæˆã®ãƒ†ã‚¹ãƒˆ
    console.log('\n=== SSMLéŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆ ===');
    const ssml = new SSMLBuilder()
      .text('ã“ã‚Œã¯')
      .emphasis('SSML', 'strong')
      .text('ã‚’ä½¿ã£ãŸéŸ³å£°åˆæˆã®')
      .pause(1)
      .prosody('ãƒ†ã‚¹ãƒˆã§ã™', { rate: 'slow', pitch: 'high' })
      .build();

    await ttsService.synthesizeSSML(ssml, './output/ssml-test.mp3');

    // 4. çµ±åˆå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n=== çµ±åˆå‡¦ç†ãƒ†ã‚¹ãƒˆ ===');
    const textProcessor = (text: string) => {
      return `å‡¦ç†çµæœ: ${text.replace(/ãˆãƒ¼|ã‚ãƒ¼|ã†ãƒ¼/g, '')}`;
    };

    const result = await integratedService.processAudioToAudio(
      './input/sample.wav',
      './output/processed.mp3',
      textProcessor
    );

    console.log('çµ±åˆå‡¦ç†å®Œäº†:', result);

  } catch (error) {
    console.error('åŸºæœ¬ä¾‹ã‚¨ãƒ©ãƒ¼:', error);
  }
}

// å®Ÿè¡Œ
basicExample();
```

### 2\. éŸ³å£°ãƒœãƒƒãƒˆã®å®Ÿè£…ä¾‹

```typescript:src/examples/voice-bot.ts
import { speechClient, ttsClient } from '../config/gcp-config';
import { SpeechToTextService } from '../services/speech-to-text.service';
import { TextToSpeechService } from '../services/text-to-speech.service';
import { IntegratedSpeechService } from '../services/integrated-speech.service';

async function voiceBotExample() {
  const sttService = new SpeechToTextService(speechClient);
  const ttsService = new TextToSpeechService(ttsClient);
  const integratedService = new IntegratedSpeechService(sttService, ttsService);

  // ã‚·ãƒ³ãƒ—ãƒ«ãªãƒœãƒƒãƒˆã®å¿œç­”ãƒ­ã‚¸ãƒƒã‚¯
  const botResponder = async (userMessage: string): Promise<string> => {
    const lowerMessage = userMessage.toLowerCase();
    
    if (lowerMessage.includes('ã“ã‚“ã«ã¡ã¯') || lowerMessage.includes('ã“ã‚“ã°ã‚“ã¯')) {
      return 'ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã©ã®ã‚ˆã†ãªã”ç”¨ä»¶ã§ã—ã‚‡ã†ã‹ï¼Ÿ';
    } else if (lowerMessage.includes('å¤©æ°—')) {
      return 'ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å¤©æ°—äºˆå ±ã®æ©Ÿèƒ½ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚';
    } else if (lowerMessage.includes('æ™‚é–“') || lowerMessage.includes('ä½•æ™‚')) {
      const now = new Date();
      const timeString = now.toLocaleTimeString('ja-JP');
      return `ç¾åœ¨ã®æ™‚åˆ»ã¯${timeString}ã§ã™ã€‚`;
    } else if (lowerMessage.includes('ã‚ã‚ŠãŒã¨ã†') || lowerMessage.includes('æ„Ÿè¬')) {
      return 'ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼ä»–ã«ã‚‚ã”è³ªå•ãŒã‚ã‚Œã°ãŠèã‹ã›ãã ã•ã„ã€‚';
    } else if (lowerMessage.includes('ã•ã‚ˆã†ãªã‚‰') || lowerMessage.includes('ãƒã‚¤ãƒã‚¤')) {
      return 'ã•ã‚ˆã†ãªã‚‰ï¼ã¾ãŸãŠè©±ã—ã¾ã—ã‚‡ã†ã€‚';
    } else {
      return 'ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã‚ˆãç†è§£ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®è¨€è‘‰ã§æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ';
    }
  };

  try {
    console.log('=== éŸ³å£°ãƒœãƒƒãƒˆé–‹å§‹ ===');
    
    const result = await integratedService.createVoiceBot(
      './input/user-question.wav',
      './output/bot-response.mp3',
      botResponder,
      'ja-JP'
    );

    console.log('ãƒœãƒƒãƒˆå‡¦ç†å®Œäº†:', result);
    console.log(`å‡¦ç†æ™‚é–“: ${result.processingTime}ms`);

  } catch (error) {
    console.error('éŸ³å£°ãƒœãƒƒãƒˆã‚¨ãƒ©ãƒ¼:', error);
  }
}

// å®Ÿè¡Œ
voiceBotExample();
```

### 3\. ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè£…ä¾‹

```typescript:src/examples/batch-processing.ts
import { speechClient, ttsClient } from '../config/gcp-config';
import { SpeechToTextService } from '../services/speech-to-text.service';
import { TextToSpeechService } from '../services/text-to-speech.service';
import { IntegratedSpeechService } from '../services/integrated-speech.service';
import { readdirSync } from 'fs';
import { join } from 'path';

async function batchProcessingExample() {
  const sttService = new SpeechToTextService(speechClient);
  const ttsService = new TextToSpeechService(ttsClient);
  const integratedService = new IntegratedSpeechService(sttService, ttsService);

  // ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ãƒ—ãƒ­ã‚»ãƒƒã‚µ
  const textNormalizer = (text: string): string => {
    return text
      .replace(/ãˆãƒ¼+|ã‚ãƒ¼+|ã†ãƒ¼+/g, '') // ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‰Šé™¤
      .replace(/\s+/g, ' ') // è¤‡æ•°ã®ç©ºç™½ã‚’1ã¤ã«
      .trim()
      .replace(/ã€‚$/, '') // æœ«å°¾ã®å¥ç‚¹ã‚’å‰Šé™¤
      + 'ã€‚ä»¥ä¸Šã§ã™ã€‚'; // çµ±ä¸€ã—ãŸçµ‚äº†è¡¨ç¾ã‚’è¿½åŠ 
  };

  try {
    console.log('=== ãƒãƒƒãƒå‡¦ç†é–‹å§‹ ===');

    // inputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    const inputDir = './input/batch';
    const outputDir = './output/batch';
    
    const audioFiles = readdirSync(inputDir)
      .filter(file => file.endsWith('.wav') || file.endsWith('.mp3'))
      .map(file => join(inputDir, file));

    console.log(`å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${audioFiles.length}`);

    // ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ
    const results = await integratedService.batchProcessAudioFiles(
      audioFiles,
      outputDir,
      textNormalizer,
      'ja-JP'
    );

    // çµæœã‚’ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    console.log('\n=== ãƒãƒƒãƒå‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ===');
    const totalTime = results.reduce((sum, result) => sum + result.processingTime, 0);
    const avgConfidence = results.reduce((sum, result) => sum + result.confidence, 0) / results.length;

    console.log(`å‡¦ç†æˆåŠŸ: ${results.length}/${audioFiles.length}`);
    console.log(`ç·å‡¦ç†æ™‚é–“: ${totalTime}ms`);
    console.log(`å¹³å‡ä¿¡é ¼åº¦: ${avgConfidence.toFixed(2)}`);
    
    // è©³ç´°çµæœã‚’CSVã§å‡ºåŠ›
    const csvContent = 'ãƒ•ã‚¡ã‚¤ãƒ«å,èªè­˜çµæœ,ä¿¡é ¼åº¦,å‡¦ç†æ™‚é–“(ms)\n' + 
      results.map(result => 
        `"${result.originalAudio}","${result.transcription}",${result.confidence},${result.processingTime}`
      ).join('\n');

    require('fs').writeFileSync('./output/batch-results.csv', csvContent, 'utf8');
    console.log('è©³ç´°çµæœã‚’batch-results.csvã«ä¿å­˜ã—ã¾ã—ãŸã€‚');

  } catch (error) {
    console.error('ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
  }
}

// å®Ÿè¡Œ
batchProcessingExample();
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1\. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥

```typescript:src/utils/error-handler.ts
export class SpeechAPIError extends Error {
  constructor(
    message: string,
    public code?: string,
    public details?: any
  ) {
    super(message);
    this.name = 'SpeechAPIError';
  }
}

export class AudioProcessingError extends Error {
  constructor(
    message: string,
    public audioFile?: string,
    public stage?: 'recognition' | 'synthesis' | 'processing'
  ) {
    super(message);
    this.name = 'AudioProcessingError';
  }
}

export const handleSpeechAPIError = (error: any): SpeechAPIError => {
  if (error.code === 3) {
    return new SpeechAPIError('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒç„¡åŠ¹ã§ã™', 'INVALID_AUDIO_FORMAT', error);
  } else if (error.code === 11) {
    return new SpeechAPIError('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“', 'AUDIO_FILE_NOT_FOUND', error);
  } else if (error.code === 8) {
    return new SpeechAPIError('APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸ', 'RESOURCE_EXHAUSTED', error);
  } else {
    return new SpeechAPIError(`APIã‚¨ãƒ©ãƒ¼: ${error.message}`, 'UNKNOWN_API_ERROR', error);
  }
};

export const withRetry = async <T>(
  operation: () => Promise<T>,
  maxRetries: number = 3,
  delay: number = 1000
): Promise<T> => {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      console.log(`ãƒªãƒˆãƒ©ã‚¤ ${attempt}/${maxRetries} - ${delay}mså¾Œã«å†å®Ÿè¡Œ`);
      await new Promise(resolve => setTimeout(resolve, delay));
      delay *= 2; // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
    }
  }
  
  throw new Error('This should never be reached');
};
```

### 2\. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```typescript:src/utils/performance-monitor.ts
export interface PerformanceMetrics {
  operationType: 'speech-to-text' | 'text-to-speech' | 'integrated';
  duration: number;
  audioLengthSeconds?: number;
  fileSize?: number;
  confidence?: number;
  languageCode: string;
  timestamp: Date;
}

export class PerformanceMonitor {
  private metrics: PerformanceMetrics[] = [];

  recordMetric(metric: PerformanceMetrics): void {
    this.metrics.push(metric);
    
    // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå¤šã™ãã‚‹å ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
    if (this.metrics.length > 1000) {
      this.metrics.shift();
    }
  }

  getAverageProcessingTime(operationType?: PerformanceMetrics['operationType']): number {
    const filteredMetrics = operationType 
      ? this.metrics.filter(m => m.operationType === operationType)
      : this.metrics;
    
    if (filteredMetrics.length === 0) return 0;
    
    return filteredMetrics.reduce((sum, m) => sum + m.duration, 0) / filteredMetrics.length;
  }

  getThroughput(operationType?: PerformanceMetrics['operationType']): number {
    const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);
    const recentMetrics = this.metrics.filter(m => m.timestamp > oneHourAgo);
    
    const filteredMetrics = operationType 
      ? recentMetrics.filter(m => m.operationType === operationType)
      : recentMetrics;
    
    return filteredMetrics.length; // 1æ™‚é–“ã‚ãŸã‚Šã®å‡¦ç†æ•°
  }

  getPerformanceReport(): string {
    const sttAvg = this.getAverageProcessingTime('speech-to-text');
    const ttsAvg = this.getAverageProcessingTime('text-to-speech');
    const integratedAvg = this.getAverageProcessingTime('integrated');
    
    return `
=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ ===
Speech-to-Textå¹³å‡å‡¦ç†æ™‚é–“: ${sttAvg.toFixed(2)}ms
Text-to-Speechå¹³å‡å‡¦ç†æ™‚é–“: ${ttsAvg.toFixed(2)}ms
çµ±åˆå‡¦ç†å¹³å‡å‡¦ç†æ™‚é–“: ${integratedAvg.toFixed(2)}ms
1æ™‚é–“ã‚ãŸã‚Šã®å‡¦ç†ä»¶æ•°: ${this.getThroughput()}ä»¶
ç·è¨˜éŒ²ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ•°: ${this.metrics.length}ä»¶
    `.trim();
  }

  exportMetricsToCSV(): string {
    const header = 'operationType,duration,audioLengthSeconds,fileSize,confidence,languageCode,timestamp\n';
    const rows = this.metrics.map(m => 
      `${m.operationType},${m.duration},${m.audioLengthSeconds || ''},${m.fileSize || ''},${m.confidence || ''},${m.languageCode},${m.timestamp.toISOString()}`
    ).join('\n');
    
    return header + rows;
  }
}

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const performanceMonitor = new PerformanceMonitor();
```

### 3\. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†

```typescript:src/utils/cache-manager.ts
import { createHash } from 'crypto';
import { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';

export class AudioCacheManager {
  private cacheDir: string;
  private maxCacheSize: number; // ãƒã‚¤ãƒˆæ•°

  constructor(cacheDir: string = './cache', maxCacheSize: number = 100 * 1024 * 1024) { // 100MB
    this.cacheDir = cacheDir;
    this.maxCacheSize = maxCacheSize;
    
    if (!existsSync(cacheDir)) {
      mkdirSync(cacheDir, { recursive: true });
    }
  }

  private generateCacheKey(text: string, options: any): string {
    const data = JSON.stringify({ text, options });
    return createHash('md5').update(data).digest('hex');
  }

  getCachedAudio(text: string, options: any): Buffer | null {
    try {
      const cacheKey = this.generateCacheKey(text, options);
      const cachePath = join(this.cacheDir, `${cacheKey}.cache`);
      
      if (existsSync(cachePath)) {
        return readFileSync(cachePath);
      }
      
      return null;
    } catch (error) {
      console.error('ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
      return null;
    }
  }

  setCachedAudio(text: string, options: any, audioBuffer: Buffer): void {
    try {
      const cacheKey = this.generateCacheKey(text, options);
      const cachePath = join(this.cacheDir, `${cacheKey}.cache`);
      
      writeFileSync(cachePath, audioBuffer);
      this.cleanupCache();
    } catch (error) {
      console.error('ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
    }
  }

  private cleanupCache(): void {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒåˆ¶é™ã‚’è¶…ãˆãŸå ´åˆã€å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    // å®Ÿè£…ã¯ç°¡ç•¥åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å®Ÿéš›ã®é‹ç”¨ã§ã¯æ›´ã«è©³ç´°ãªå®Ÿè£…ãŒå¿…è¦
  }

  getCacheStats(): { files: number; totalSize: number } {
    try {
      const { readdirSync, statSync } = require('fs');
      const files = readdirSync(this.cacheDir).filter(f => f.endsWith('.cache'));
      const totalSize = files.reduce((size, file) => {
        return size + statSync(join(this.cacheDir, file)).size;
      }, 0);
      
      return { files: files.length, totalSize };
    } catch (error) {
      return { files: 0, totalSize: 0 };
    }
  }
}

export const audioCacheManager = new AudioCacheManager();
```

## æ–™é‡‘æœ€é©åŒ–ã¨ã‚³ã‚¹ãƒˆç®¡ç†

### 1\. ã‚³ã‚¹ãƒˆè¿½è·¡ã‚·ã‚¹ãƒ†ãƒ 

```typescript:src/utils/cost-tracker.ts
export interface CostInfo {
  operationType: 'speech-to-text' | 'text-to-speech';
  units: number; // STT: 15ç§’å˜ä½, TTS: æ–‡å­—æ•°
  estimatedCost: number; // USD
  timestamp: Date;
}

export class CostTracker {
  private costs: CostInfo[] = [];
  
  // 2024å¹´æ™‚ç‚¹ã®æ¦‚ç®—æ–™é‡‘ï¼ˆå®Ÿéš›ã®æ–™é‡‘ã¯å¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰
  private readonly PRICING = {
    'speech-to-text': 0.006, // $0.006 per 15-second interval
    'text-to-speech': 0.000004, // $0.000004 per character
  } as const;

  recordCost(operationType: CostInfo['operationType'], units: number): void {
    const estimatedCost = units * this.PRICING[operationType];
    
    this.costs.push({
      operationType,
      units,
      estimatedCost,
      timestamp: new Date(),
    });
  }

  getDailyCost(date?: Date): number {
    const targetDate = date || new Date();
    const startOfDay = new Date(targetDate);
    startOfDay.setHours(0, 0, 0, 0);
    
    const endOfDay = new Date(targetDate);
    endOfDay.setHours(23, 59, 59, 999);

    return this.costs
      .filter(cost => cost.timestamp >= startOfDay && cost.timestamp <= endOfDay)
      .reduce((total, cost) => total + cost.estimatedCost, 0);
  }

  getMonthlyCost(year: number, month: number): number {
    const startOfMonth = new Date(year, month - 1, 1);
    const endOfMonth = new Date(year, month, 0, 23, 59, 59, 999);

    return this.costs
      .filter(cost => cost.timestamp >= startOfMonth && cost.timestamp <= endOfMonth)
      .reduce((total, cost) => total + cost.estimatedCost, 0);
  }

  getCostByOperation(operationType: CostInfo['operationType']): number {
    return this.costs
      .filter(cost => cost.operationType === operationType)
      .reduce((total, cost) => total + cost.estimatedCost, 0);
  }

  getCostReport(): string {
    const totalCost = this.costs.reduce((total, cost) => total + cost.estimatedCost, 0);
    const dailyCost = this.getDailyCost();
    const sttCost = this.getCostByOperation('speech-to-text');
    const ttsCost = this.getCostByOperation('text-to-speech');

    return `
=== ã‚³ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ ===
ç·ã‚³ã‚¹ãƒˆ: $${totalCost.toFixed(4)}
ä»Šæ—¥ã®ã‚³ã‚¹ãƒˆ: $${dailyCost.toFixed(4)}
Speech-to-Text: $${sttCost.toFixed(4)}
Text-to-Speech: $${ttsCost.toFixed(4)}
ç·å–å¼•æ•°: ${this.costs.length}ä»¶
    `.trim();
  }

  exportCostData(): string {
    const header = 'operationType,units,estimatedCost,timestamp\n';
    const rows = this.costs.map(cost => 
      `${cost.operationType},${cost.units},${cost.estimatedCost},${cost.timestamp.toISOString()}`
    ).join('\n');
    
    return header + rows;
  }
}

export const costTracker = new CostTracker();
```

### 2\. æœ€é©åŒ–ã•ã‚ŒãŸã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹

```typescript:src/services/optimized-speech.service.ts
import { SpeechToTextService } from './speech-to-text.service';
import { TextToSpeechService } from './text-to-speech.service';
import { audioCacheManager } from '../utils/cache-manager';
import { costTracker } from '../utils/cost-tracker';
import { performanceMonitor } from '../utils/performance-monitor';

export class OptimizedSpeechService {
  private sttService: SpeechToTextService;
  private ttsService: TextToSpeechService;

  constructor(sttService: SpeechToTextService, ttsService: TextToSpeechService) {
    this.sttService = sttService;
    this.ttsService = ttsService;
  }

  async synthesizeTextWithCache(
    text: string,
    outputPath: string,
    options: any = {}
  ): Promise<void> {
    const startTime = Date.now();

    try {
      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
      const cachedAudio = audioCacheManager.getCachedAudio(text, options);
      if (cachedAudio) {
        require('fs').writeFileSync(outputPath, cachedAudio);
        console.log('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã¾ã—ãŸ');
        
        performanceMonitor.recordMetric({
          operationType: 'text-to-speech',
          duration: Date.now() - startTime,
          languageCode: options.languageCode || 'ja-JP',
          timestamp: new Date(),
        });
        
        return;
      }

      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã¯APIã‚’å‘¼ã³å‡ºã—
      await this.ttsService.synthesizeText(text, outputPath, options);
      
      // çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
      const audioBuffer = require('fs').readFileSync(outputPath);
      audioCacheManager.setCachedAudio(text, options, audioBuffer);
      
      // ã‚³ã‚¹ãƒˆã‚’è¨˜éŒ²
      costTracker.recordCost('text-to-speech', text.length);
      
      // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²
      performanceMonitor.recordMetric({
        operationType: 'text-to-speech',
        duration: Date.now() - startTime,
        languageCode: options.languageCode || 'ja-JP',
        timestamp: new Date(),
      });

    } catch (error) {
      console.error('æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  async transcribeWithOptimization(
    audioFilePath: string,
    languageCode: string = 'ja-JP'
  ): Promise<string> {
    const startTime = Date.now();

    try {
      const result = await this.sttService.transcribeAudioFile(audioFilePath, languageCode);
      
      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’æ¦‚ç®—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æï¼‰
      const audioLengthSeconds = 30; // ã‚µãƒ³ãƒ—ãƒ«å€¤
      const units = Math.ceil(audioLengthSeconds / 15); // 15ç§’å˜ä½ã§èª²é‡‘
      
      // ã‚³ã‚¹ãƒˆã‚’è¨˜éŒ²
      costTracker.recordCost('speech-to-text', units);
      
      // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²
      performanceMonitor.recordMetric({
        operationType: 'speech-to-text',
        duration: Date.now() - startTime,
        audioLengthSeconds,
        languageCode,
        timestamp: new Date(),
      });

      return result;
    } catch (error) {
      console.error('æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  getOptimizationReport(): string {
    const cacheStats = audioCacheManager.getCacheStats();
    const costReport = costTracker.getCostReport();
    const perfReport = performanceMonitor.getPerformanceReport();

    return `
=== æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ ===

${costReport}

=== ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ ===
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${cacheStats.files}
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: ${(cacheStats.totalSize / 1024 / 1024).toFixed(2)}MB

${perfReport}
    `.trim();
  }
}
```

## å®Ÿé‹ç”¨ã§ã®è¨­å®šã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### 1\. ç’°å¢ƒåˆ¥è¨­å®šç®¡ç†

```typescript:src/config/environment.ts
export interface EnvironmentConfig {
  gcpProjectId: string;
  gcpCredentialsPath: string;
  gcpLocation: string;
  gcsBucketName: string;
  cacheDirectory: string;
  maxCacheSize: number;
  retryAttempts: number;
  logLevel: 'debug' | 'info' | 'warn' | 'error';
  enablePerformanceMonitoring: boolean;
  enableCostTracking: boolean;
}

const developmentConfig: EnvironmentConfig = {
  gcpProjectId: process.env.GCP_PROJECT_ID || 'dev-project',
  gcpCredentialsPath: process.env.GOOGLE_APPLICATION_CREDENTIALS || './dev-credentials.json',
  gcpLocation: 'asia-northeast1',
  gcsBucketName: process.env.GCS_BUCKET_NAME || 'dev-speech-bucket',
  cacheDirectory: './cache/dev',
  maxCacheSize: 50 * 1024 * 1024, // 50MB
  retryAttempts: 3,
  logLevel: 'debug',
  enablePerformanceMonitoring: true,
  enableCostTracking: true,
};

const productionConfig: EnvironmentConfig = {
  gcpProjectId: process.env.GCP_PROJECT_ID || '',
  gcpCredentialsPath: process.env.GOOGLE_APPLICATION_CREDENTIALS || '',
  gcpLocation: process.env.GCP_LOCATION || 'asia-northeast1',
  gcsBucketName: process.env.GCS_BUCKET_NAME || '',
  cacheDirectory: '/var/cache/speech',
  maxCacheSize: 500 * 1024 * 1024, // 500MB
  retryAttempts: 5,
  logLevel: 'info',
  enablePerformanceMonitoring: true,
  enableCostTracking: true,
};

export const getConfig = (): EnvironmentConfig => {
  const env = process.env.NODE_ENV || 'development';
  
  switch (env) {
    case 'production':
      return productionConfig;
    case 'development':
    default:
      return developmentConfig;
  }
};

export const config = getConfig();
```

### 2\. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

```typescript:src/health/health-checker.ts
import { speechClient, ttsClient } from '../config/gcp-config';

export interface HealthStatus {
  service: string;
  status: 'healthy' | 'unhealthy' | 'degraded';
  latency?: number;
  error?: string;
  timestamp: Date;
}

export class HealthChecker {
  async checkSpeechToTextHealth(): Promise<HealthStatus> {
    const startTime = Date.now();
    
    try {
      // ç°¡å˜ãªãƒ€ãƒŸãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§APIã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
      await speechClient.listVoices?.({});
      
      const latency = Date.now() - startTime;
      
      return {
        service: 'speech-to-text',
        status: latency < 5000 ? 'healthy' : 'degraded',
        latency,
        timestamp: new Date(),
      };
    } catch (error) {
      return {
        service: 'speech-to-text',
        status: 'unhealthy',
        latency: Date.now() - startTime,
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date(),
      };
    }
  }

  async checkTextToSpeechHealth(): Promise<HealthStatus> {
    const startTime = Date.now();
    
    try {
      // éŸ³å£°ãƒªã‚¹ãƒˆã®å–å¾—ã§APIã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
      await ttsClient.listVoices({ languageCode: 'ja-JP' });
      
      const latency = Date.now() - startTime;
      
      return {
        service: 'text-to-speech',
        status: latency < 5000 ? 'healthy' : 'degraded',
        latency,
        timestamp: new Date(),
      };
    } catch (error) {
      return {
        service: 'text-to-speech',
        status: 'unhealthy',
        latency: Date.now() - startTime,
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date(),
      };
    }
  }

  async performHealthCheck(): Promise<HealthStatus[]> {
    const checks = await Promise.allSettled([
      this.checkSpeechToTextHealth(),
      this.checkTextToSpeechHealth(),
    ]);

    return checks.map(result => 
      result.status === 'fulfilled' ? result.value : {
        service: 'unknown',
        status: 'unhealthy' as const,
        error: 'Health check failed',
        timestamp: new Date(),
      }
    );
  }

  async getHealthReport(): Promise<string> {
    const healthStatuses = await this.performHealthCheck();
    
    const report = healthStatuses.map(status => 
      `${status.service}: ${status.status}${status.latency ? ` (${status.latency}ms)` : ''}${status.error ? ` - ${status.error}` : ''}`
    ).join('\n');

    return `=== ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ ===\n${report}`;
  }
}

export const healthChecker = new HealthChecker();
```

### 3\. Express.jsã¨ã®çµ±åˆä¾‹

```typescript:src/app.ts
import express from 'express';
import multer from 'multer';
import { speechClient, ttsClient } from './config/gcp-config';
import { OptimizedSpeechService } from './services/optimized-speech.service';
import { SpeechToTextService } from './services/speech-to-text.service';
import { TextToSpeechService } from './services/text-to-speech.service';
import { healthChecker } from './health/health-checker';
import { config } from './config/environment';

const app = express();
const upload = multer({ dest: 'uploads/' });

// ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
const sttService = new SpeechToTextService(speechClient);
const ttsService = new TextToSpeechService(ttsClient);
const optimizedService = new OptimizedSpeechService(sttService, ttsService);

app.use(express.json());

// ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.get('/health', async (req, res) => {
  try {
    const healthReport = await healthChecker.getHealthReport();
    res.json({ status: 'ok', report: healthReport });
  } catch (error) {
    res.status(500).json({ status: 'error', message: 'Health check failed' });
  }
});

// éŸ³å£°èªè­˜ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.post('/api/speech-to-text', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™' });
    }

    const { languageCode = 'ja-JP' } = req.body;
    const transcription = await optimizedService.transcribeWithOptimization(
      req.file.path,
      languageCode
    );

    res.json({ transcription });
  } catch (error) {
    console.error('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', error);
    res.status(500).json({ error: 'éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ' });
  }
});

// éŸ³å£°åˆæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.post('/api/text-to-speech', async (req, res) => {
  try {
    const { text, options = {} } = req.body;
    
    if (!text) {
      return res.status(400).json({ error: 'ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ã§ã™' });
    }

    const outputPath = `./temp/${Date.now()}.mp3`;
    await optimizedService.synthesizeTextWithCache(text, outputPath, options);

    res.download(outputPath, (err) => {
      if (err) console.error('ãƒ•ã‚¡ã‚¤ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼:', err);
      // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      require('fs').unlinkSync(outputPath);
    });
  } catch (error) {
    console.error('éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:', error);
    res.status(500).json({ error: 'éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ' });
  }
});

// æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.get('/api/optimization-report', (req, res) => {
  try {
    const report = optimizedService.getOptimizationReport();
    res.json({ report });
  } catch (error) {
    console.error('ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼:', error);
    res.status(500).json({ error: 'ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ' });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`ã‚µãƒ¼ãƒãƒ¼ãŒãƒãƒ¼ãƒˆ${PORT}ã§èµ·å‹•ã—ã¾ã—ãŸ`);
  console.log(`ç’°å¢ƒ: ${process.env.NODE_ENV || 'development'}`);
  console.log(`GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ${config.gcpProjectId}`);
});

export default app;
```

## ã¾ã¨ã‚

GCPã®Speech-to-Text APIã¨Text-to-Speech APIã‚’ä½¿ãˆã°ã€é«˜å“è³ªãªéŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’æ¯”è¼ƒçš„ç°¡å˜ã«æ§‹ç¯‰ã§ãã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚

**ğŸ¯ ã“ã®è¨˜äº‹ã§å®Ÿè£…ã—ãŸä¸»è¦æ©Ÿèƒ½**

>* **åŸºæœ¬çš„ãªéŸ³å£°èªè­˜ãƒ»åˆæˆæ©Ÿèƒ½**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¤‰æ›æ©Ÿèƒ½
>* **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®èªè­˜ã‚·ã‚¹ãƒ†ãƒ 
>* **çµ±åˆéŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ **: STTã¨TTSã‚’çµ„ã¿åˆã‚ã›ãŸé«˜åº¦ãªå‡¦ç†
>* **SSMLå¯¾å¿œ**: è¡¨ç¾è±Šã‹ãªéŸ³å£°åˆæˆæ©Ÿèƒ½
>* **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ç›£è¦–æ©Ÿèƒ½
>* **ã‚³ã‚¹ãƒˆç®¡ç†**: æ–™é‡‘è¿½è·¡ã¨æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
>* **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œ**: è¨­å®šç®¡ç†ã€ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã€APIåŒ–

**ğŸ’¡ å®Ÿè£…æ™‚ã®ãƒã‚¤ãƒ³ãƒˆ**

>1. **é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: APIã®åˆ¶é™ã‚„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚¨ãƒ©ãƒ¼ã«å¯¾å¿œ
>2. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨**: åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã®éŸ³å£°åˆæˆçµæœã‚’å†åˆ©ç”¨ã—ã¦ã‚³ã‚¹ãƒˆå‰Šæ¸›
>3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–**: å‡¦ç†æ™‚é–“ã¨æˆåŠŸç‡ã‚’è¿½è·¡ã—ã¦å“è³ªå‘ä¸Š
>4. **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**: ä½¿ç”¨é‡ã‚’è¿½è·¡ã—ã¦äºˆç®—ç®¡ç†ã‚’å®Ÿç¾
>5. **æŸ”è»Ÿãªè¨­å®šç®¡ç†**: ç’°å¢ƒåˆ¥ã®è¨­å®šã§é–‹ç™ºã‹ã‚‰æœ¬ç•ªã¾ã§å¯¾å¿œ

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€WebSocket ã‚’ä½¿ã£ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚„ã€è¤‡æ•°è¨€èªã®åŒæ™‚å¯¾å¿œã€ã•ã‚‰ã«é«˜åº¦ãªéŸ³å£°è§£ææ©Ÿèƒ½ã®å®Ÿè£…ã‚’æ¤œè¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

Google Cloudã®Speech AIã‚µãƒ¼ãƒ“ã‚¹ã¯ä»Šå¾Œã‚‚æ©Ÿèƒ½æ‹¡å¼µãŒäºˆæƒ³ã•ã‚Œã‚‹ãŸã‚ã€ç¶™ç¶šçš„ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æœ€æ–°æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ã„ãã“ã¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™ï¼